{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Focus:\n",
    "\n",
    "This notebook focuses on how external factors influence accident rates and identifies key high-risk locations.\n",
    "\n",
    "- **Impact of External Factors:**\n",
    "    - Analyze how weather conditions, holidays, and weekends affect accident frequency and severity.\n",
    "    \n",
    "- **Key Locations:**\n",
    "    - Identify the most dangerous intersections or streets.\n",
    "    - Map accident severity geographically to highlight high-risk areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and manipulation\n",
    "import dask.dataframe as dd                         \n",
    "import pandas as pd                                 \n",
    "import numpy as np                                  \n",
    "import re                                           \n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt                     \n",
    "from matplotlib.ticker import StrMethodFormatter     \n",
    "import seaborn as sns                              \n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder      \n",
    "\n",
    "# Memory management\n",
    "import gc                                         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tHow does weather affect accident rates?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIRST IDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = dd.read_parquet('/Users/er/Desktop/Data Analysis/Projects/Python/US Accidents/USTrafficAccidents/Data/Parquet/US_Accidents_March23.parquet')\n",
    "\n",
    "# Filter relevant columns\n",
    "df_filtered = df[['Severity', 'Weather_Condition']].dropna()\n",
    "\n",
    "# Compute the filtered DataFrame\n",
    "df_filtered = df_filtered.compute()\n",
    "\n",
    "# Encode the 'Weather_Condition' using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df_filtered['Weather_Condition_Encoded'] = label_encoder.fit_transform(df_filtered['Weather_Condition'])\n",
    "\n",
    "# Loop through each severity level from 1 to 4\n",
    "for severity in range(1, 5):\n",
    "    # Filter the DataFrame for the current severity level\n",
    "    df_severity = df_filtered[df_filtered['Severity'] == severity]\n",
    "\n",
    "    # Count occurrences of each weather condition\n",
    "    severity_counts = df_severity['Weather_Condition'].value_counts()\n",
    "    total_severity = severity_counts.sum()  # Total count of weather conditions\n",
    "    nan_count = df_severity['Weather_Condition'].isna().sum()  # Count of NaN values\n",
    "\n",
    "    # Get the top 5 weather conditions\n",
    "    top_5_severity = severity_counts.nlargest(5)\n",
    "    print(f\"Top 5 Weather Conditions for Severity Level {severity}:\\n{top_5_severity}\")\n",
    "\n",
    "    # Plotting the bar chart for top 5 weather conditions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_5_severity.plot(kind='bar', color='skyblue')\n",
    "\n",
    "    # Formatting the bar plot\n",
    "    plt.title(f'Top 5 Weather Conditions in Severity Level {severity} Accidents')\n",
    "    plt.xlabel('Weather Condition')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))  # Format y-axis as integer\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "    plt.show()\n",
    "\n",
    "    # Prepare data for heatmap\n",
    "    # Filter the DataFrame to include only the current severity level and top 5 weather conditions\n",
    "    df_top5 = df_filtered[df_filtered['Weather_Condition'].isin(top_5_severity.index)]\n",
    "\n",
    "    # Create a pivot table to count occurrences of each weather condition by severity\n",
    "    pivot_table = pd.crosstab(df_top5['Weather_Condition'], df_top5['Severity'])\n",
    "\n",
    "    # Generate the heatmap for top 5 weather conditions by severity\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(pivot_table, annot=True, fmt='d', cmap='YlGnBu', cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Heatmap of Top 5 Weather Conditions by Accident Severity Level {severity}')\n",
    "    plt.xlabel('Severity Level')\n",
    "    plt.ylabel('Weather Condition')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "    plt.show()\n",
    "\n",
    "# Calculate the correlation matrix for severity and encoded weather conditions\n",
    "correlation_matrix = df_filtered[['Severity', 'Weather_Condition_Encoded']].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\\n\", correlation_matrix)\n",
    "\n",
    "# Plot the heatmap for the correlation matrix\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', cbar_kws={'label': 'Correlation Coefficient'})\n",
    "plt.title('Correlation between Severity and Weather Conditions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SECOND IDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = dd.read_parquet('/Users/er/Desktop/Data Analysis/Projects/Python/US Accidents/USTrafficAccidents/Data/Parquet/US_Accidents_March23.parquet')\n",
    "\n",
    "# Filter for relevant columns\n",
    "df_filtered = df[['Severity', 'Weather_Condition']]\n",
    "\n",
    "# Drop rows with NaN values in the filtered DataFrame\n",
    "df_filtered = df_filtered.dropna()\n",
    "\n",
    "# Compute the filtered DataFrame\n",
    "df_filtered = df_filtered.compute()\n",
    "\n",
    "# Count occurrences of each weather condition\n",
    "weather_counts = df_filtered['Weather_Condition'].value_counts()\n",
    "\n",
    "# Get the top 5 weather conditions\n",
    "top_5_weather = weather_counts.head(5).index\n",
    "\n",
    "# Filter the DataFrame to include only the top 5 weather conditions\n",
    "df_top5 = df_filtered[df_filtered['Weather_Condition'].isin(top_5_weather)]\n",
    "\n",
    "# Create a pivot table to count occurrences of each weather condition by severity\n",
    "pivot_table = pd.crosstab(df_top5['Weather_Condition'], df_top5['Severity'])\n",
    "\n",
    "# Generate the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, fmt='d', cmap='YlGnBu', cbar_kws={'label': 'Count'})\n",
    "plt.title('Heatmap of Top 5 Weather Conditions by Accident Severity')\n",
    "plt.xlabel('Severity Level')\n",
    "plt.ylabel('Weather Condition')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tDo accidents increase during specific holidays or weekends?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOTTA CODE THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tCan you visualize the top 10 most dangerous intersections or streets in the U.S.?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = dd.read_parquet('/Users/er/Desktop/Data Analysis/Projects/Python/US Accidents/USTrafficAccidents/Data/Parquet/US_Accidents_March23.parquet')\n",
    "\n",
    "# Define a function to classify street types\n",
    "def classify_street_type(street):\n",
    "    if pd.isna(street):  # Check for NA values\n",
    "        return 'Unknown'  # Assign 'Unknown' for NA values\n",
    "    elif re.search(r'\\bSt\\b|\\bStreet\\b|\\bSt.\\b|\\bS\\b', street, re.IGNORECASE):\n",
    "        return 'Street'\n",
    "    elif re.search(r'\\bAve\\b|\\bAvenue\\b|\\bAv.\\b|\\bA.\\b', street, re.IGNORECASE):\n",
    "        return 'Avenue'\n",
    "    elif re.search(r'\\bDr\\b|\\bDrive\\b|\\bDr.\\b|\\bD.\\b', street, re.IGNORECASE):\n",
    "        return 'Drive'\n",
    "    elif re.search(r'\\bPike\\b|\\bPk\\b|\\bP.\\b', street, re.IGNORECASE):\n",
    "        return 'Pike'\n",
    "    elif re.search(r'\\bHighway\\b|\\bHwy\\b|\\bHwy.\\b|\\bH.\\b', street, re.IGNORECASE):\n",
    "        return 'Highway'\n",
    "    elif re.search(r'\\bBlvd\\b|\\bBoulevard\\b|\\bBlvd.\\b|\\bB.\\b', street, re.IGNORECASE):\n",
    "        return 'Boulevard'\n",
    "    elif re.search(r'\\bLn\\b|\\bLane\\b|\\bLn.\\b|\\bL.\\b', street, re.IGNORECASE):\n",
    "        return 'Lane'\n",
    "    elif re.search(r'\\bCt\\b|\\bCourt\\b|\\bCt.\\b|\\bC.\\b', street, re.IGNORECASE):\n",
    "        return 'Court'\n",
    "    elif re.search(r'\\bPl\\b|\\bPlace\\b|\\bPl.\\b|\\bP.\\b', street, re.IGNORECASE):\n",
    "        return 'Place'\n",
    "    elif re.search(r'\\bTer\\b|\\bTerrace\\b|\\bTer.\\b|\\bT.\\b', street, re.IGNORECASE):\n",
    "        return 'Terrace'\n",
    "    elif re.search(r'\\bCir\\b|\\bCircle\\b|\\bCir.\\b|\\bC.\\b', street, re.IGNORECASE):\n",
    "        return 'Circle'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the classification function to the 'Street' column\n",
    "df['Street_Type'] = df['Street'].map(classify_street_type, meta=('x', 'object'))\n",
    "\n",
    "# Count NA values in 'Street' column\n",
    "na_count = df['Street'].isna().sum().compute()\n",
    "print(f\"Number of NA values in 'Street' column: {na_count}\")\n",
    "\n",
    "# Aggregate accidents by street type\n",
    "accidents_by_street_type = df.groupby('Street_Type')['Severity'].count().compute()\n",
    "\n",
    "# Print the counts per street type\n",
    "print(\"\\nCounts of accidents by street type:\")\n",
    "print(accidents_by_street_type)\n",
    "\n",
    "# Sort the results for better visualization\n",
    "accidents_by_street_type = accidents_by_street_type.sort_values(ascending=False)\n",
    "\n",
    "# Ensure the total count matches expected shape\n",
    "total_accidents = accidents_by_street_type.sum()\n",
    "print(f\"\\nTotal accidents counted: {total_accidents}\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "accidents_by_street_type.plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title('Accidents by Street Type')\n",
    "plt.xlabel('Street Type')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tHow does the severity of accidents differ when mapped geographically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TABLEAU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataTools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
